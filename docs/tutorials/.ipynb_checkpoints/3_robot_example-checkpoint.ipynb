{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Running an Experiment with Intprim ROS\n",
    "\n",
    "This tutorial will demonstrate how to setup an experiment, uitilize the Intprim ROS Framework, and train a model. A simulator (CoppeliaSim) with two robots will be used so that users can test out the framework without the need for human subjects or physical robots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## 1.0 Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is assumed that you have the following pre-requisites satisfied:\n",
    "- Intprim Container running, OR:\n",
    "------------------------\n",
    "- ROS installed\n",
    "- Intprim Library installed\n",
    "- Intprim Framework ROS installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Creating Experiment - Joe talks about creating experiment files for CoppeliaSim and points to 5_creating_new_experiment\n",
    "\n",
    "## 1.1 Creating Experiment Files\n",
    "\n",
    "paste the experiment files here\n",
    "\n",
    "explain the important variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## **1.2 Collecting Data** \n",
    "Every HRI scenario is unique! Research groups, roboticists, and hobbyists tend to have different lab environments. These enviornments may contain unique motion capture equipment, robots, and people of various heights/shapes. For this reason, it is challenging to repeat experiments in new environments and on different robots or subjects since the state space is different. Intprim aims to make the robot learning process easier by providing a framework for quickly learning interactions between a robot and human partner. One of the benefits of using Intprim is that only the trajectories for each DOF in the robot and partner are needed for an interaction to be learned.\n",
    "\n",
    "### **Example Demonstrations:**\n",
    "To get started, you will need to conduct experiments consisting of a subject and a robot interacting. These recorded experiments will be used to train the Bayesian Interaction Primitives model. We expect that the robot's and human's DOFs will be published as a rostopic during the interaction. During the demonstration, Intprim will record the interaction and save it as a rosbag. Here is an example of a simple interaction below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joe's section- Instead of collecting data, we are using the rosbags (discussed above) from CoppeliaSim, but the concept is similar to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<img src=\"../media/t1.png\" width=\"1000\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "At t = 1, the degrees of freedom for the robot and human partner are captured as a column vector. Because every DOF is published as a ROS topic that is time stamped, this information can be easily recorded and extracted. In the diagram above, the coordinates for each DOF are recorded; however, in practice, we record the joint angles of the robot. The key takeaway is all DOFs are treated equally and may be in different units (radians, centimeters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<img src=\"../media/t2.png\" width=\"1000\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "At t = 2, the degrees of freedom for the robot and human partner are captured as a column vector again. Notice how the subject and robot are in slightly different poses, which is captured by x2. These time steps define the points along the trajectory, so the vectors will be concatenated into matrix form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<img src=\"../media/matrix.png\" width=\"1000\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Once the interaction is complete, the trajectories and recorded data will be stored in a rosbag. Since the rosbag includes time-stamped data, it can be viewed as a matrix (with every column representing a time slice). So far, we have discussed the data collection process and described the parameter files. After recording these rosbags, we will need to convert them into .csv format in order to train a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<img src=\"../media/diagram.png\" width=\"1000\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "This diagram depicts the high-level execution flow for using Intprim. In the next section, we will cover how to convert the recorded demonstrations into .csv format. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joe: Coppelia Sim Stuff Tutorial/Overview- here or above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Should we repeat the following section? Or have them refer to notebook 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## **1.3 Training** - Converting rosbags to CSV\n",
    "1. The Interactive Application is started and the user selects an experiment followed by the \"Train\" option.\n",
    "\n",
    "`Please select a scenario category:\n",
    "    [0] Train\n",
    "    [1] Test`\n",
    "\n",
    "2. The data can be exported either to a rosbag (recommended) or a CSV file. It is always recommended to choose rosbag to save the raw data, as it can always be later exported to a CSV. Exporting directly to CSV may cause information loss if the user-specified observation frequency is less than a sensor's sampling frequency.\n",
    "\n",
    "\n",
    "`Please select a scenario action:\n",
    "  [0] Export data to rosbag\n",
    "  [1] Export data to csv\n",
    "  [2] Export data to csv from rosbag\n",
    "  [3] Delete last rosbag`\n",
    "\n",
    "3. If export to a rosbag is selected, the experiment can be triggered via the space bar which will then begin recording. The experiment will stop when either the timeout specified in experiments.yaml is reached or the space bar is pressed.\n",
    "\n",
    "`Prepare to execute arbitrary trajectory...\n",
    "Please get ready and press [space] to begin demonstration.\n",
    "Executing demonstration in 5 seconds. Get ready...`\n",
    "\n",
    "3. Once rosbags are collected, they will need to be exported to a CSV file for further processing by IntPrim. To do so, enter the training menu again and this time select \"Export data to csv from rosbag\" and specify the directory where the rosbags are stored. Note that the prefix on the file names must be the same as the experiment prefix defined in experiments.yaml (and what exporting to rosbag automatically defines).\n",
    "\n",
    "4. Once the CSV files are exported, open up the graphical dashboard to train a BIP model. To do so, press \"d\" on the main menu of the Interaction Application CLI:\n",
    "<img src=\"../media/dashboard.png\" width=\"1000\" />\n",
    "\n",
    "5. Press \"Select Demonstrations\", select all of the exported CSV files, and then press \"Open\". Select all of the files that appear in the window by clicking them, and then select \"Train Demonstration(s)\" followed by \"Export Primitive\". Lastly, we must determine the appropriate observation noise, so with the files still selected press \"Export Observation Noise\" and select \"Ok\".\n",
    "\n",
    "## **1.4 Testing**\n",
    "\n",
    "1. With a BIP model trained, it is a relatively straightforward process to test against pre-recorded or real-time data. Launch the Interaction Application CLI, select the experiment, and this time select the \"Test\" option.\n",
    "\n",
    "`Please select a scenario action:\n",
    "  [0] Export data to rosbag\n",
    "  [1] Do not export\n",
    "  [2] Test from rosbag\n",
    "  [3] Test from csv`\n",
    "\n",
    "2. From here, we can test against real-time data by selecting one of the first two options, \"Export data to rosbag\" or \"Do not export\", in which case a rosbag will either be recorded for the test interaction or not.\n",
    "\n",
    "3. To test against pre-recorded rosbags, select \"Test from rosbag\" and enter the directory where the rosbags are stored.\n",
    "\n",
    "4. To test against exported CSV files, select \"Test from csv\" and enter the directory where the CSV files are stored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Expected Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain CoppeliaSim Results here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  },
  "name": "robot_example_3.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
